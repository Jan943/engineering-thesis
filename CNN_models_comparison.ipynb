{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpWiKxjj4dk5"
      },
      "source": [
        "# Import bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scG4Am-Iahg5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import urllib3\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcZTIIXB5jGa"
      },
      "source": [
        "# Przygotowanie danych do trenowania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjTYhaGT2SYL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\",)\n",
        "%cd /content/gdrive/MyDrive/ml_project/OIDv4_ToolKit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ4maJtiahhA"
      },
      "outputs": [],
      "source": [
        "def get_coco_labels():\n",
        "    http = urllib3.PoolManager()\n",
        "    r = http.request('GET', 'https://raw.githubusercontent.com/amikelive/coco-labels/master/coco-labels-paper.txt')\n",
        "    dane = r.data.decode('UTF-8')\n",
        "    my_data = dane.split('\\n')\n",
        "    # coco = {1: my_data[0], 2:my_data[12], 3:my_data[76]}\n",
        "    coco = {i+1: my_data[i] for i in range(0,len(my_data))}\n",
        "    coco.pop(91)\n",
        "    return coco    \n",
        "\n",
        "def get_downloadable_labels_str(coco):\n",
        "    d = {value:1 for value in coco.values()}\n",
        "\n",
        "    # Google's Open Images V4 dataset    Microsoft's COCO dataset\n",
        "    d[\"traffic sign\"] = d.pop(\"street sign\")\n",
        "    d[\"bull\"] = d.pop(\"cow\")\n",
        "    d[\"glasses\"] = d.pop(\"eye glasses\")\n",
        "    d[\"boot\"] = d.pop(\"shoe\")\n",
        "    d[\"hair dryer\"] = d.pop(\"hair drier\")\n",
        "    d[\"doughnut\"] = d.pop(\"donut\")\n",
        "    d[\"microwave oven\"] = d.pop(\"microwave\")\n",
        "    d[\"telephone\"] = d.pop(\"cell phone\")\n",
        "    d[\"computer keyboard\"] = d.pop(\"keyboard\")\n",
        "    d[\"remote control\"] = d.pop(\"remote\")\n",
        "    d[\"computer mouse\"] = d.pop(\"mouse\")\n",
        "    d[\"television\"] = d.pop(\"tv\")\n",
        "    d[\"Kitchen dining room table\"] = d.pop(\"dining table\")\n",
        "    d[\"plant\"] = d.pop(\"potted plant\")\n",
        "    d[\"ski\"] = d.pop(\"skis\")\n",
        "    d[\"volleyball\"] = d.pop(\"sports ball\")\n",
        "    d[\"coffee cup\"] = d.pop(\"cup\")\n",
        "    d[\"flying disc\"] = d.pop(\"frisbee\")\n",
        "\n",
        "    labels = list(d.keys())\n",
        "    lb = [x.capitalize() for x in labels]\n",
        "    lb1 = [label.replace(\" \",\"_\") for label in lb]\n",
        "    str1 = \" \"\n",
        "    names = str1.join(lb1)\n",
        "    print(names)\n",
        "    return names\n",
        "\n",
        "def get_paths_to_photos_and_labels(dataset_path = \"OID/Dataset/train\"):\n",
        "    directory_contents = os.listdir(dataset_path)\n",
        "    class_path_dict = {}\n",
        "    for subdirectory in directory_contents:\n",
        "        images = os.listdir(dataset_path + \"/\" + subdirectory)\n",
        "        for image_ in images:\n",
        "            if image_.endswith(\".jpg\"):\n",
        "                full_image_path = dataset_path + \"/\" + subdirectory + \"/\" + image_\n",
        "                if subdirectory.lower() in class_path_dict:\n",
        "                    class_path_dict[subdirectory.lower()].append(full_image_path)\n",
        "                else:\n",
        "                    class_path_dict[subdirectory.lower()] = [full_image_path]\n",
        "    return class_path_dict\n",
        "\n",
        "def get_all_images_metadata_dict(path= \"OID/csv_folder/train-annotations-bbox.csv\"):\n",
        "    my_dict = {}\n",
        "    correct_class_id = class_id_to_coco_label_map.keys()\n",
        "    with open(path, mode='r') as infile:\n",
        "        reader = csv.reader(infile)\n",
        "        for row in reader:\n",
        "            if row[0] not in my_dict:\n",
        "                if row[2] in correct_class_id:\n",
        "                    my_dict[row[0]] = []\n",
        "                    my_dict[row[0]].append(row[1:])\n",
        "            else:\n",
        "                if row[2] in correct_class_id:\n",
        "                    my_dict[row[0]].append(row[1:])\n",
        "    return my_dict\n",
        "\n",
        "def get_class_id_to_open_image_label_map(path = \"OID/csv_folder/class-descriptions-boxable.csv\"):\n",
        "    f = open(path)\n",
        "    class_map = {}\n",
        "    for line in f:\n",
        "        data_line = line.rstrip().split(',')\n",
        "        class_map[data_line[0]] = data_line[1]\n",
        "    return class_map\n",
        "\n",
        "def convert_open_image_label_to_coco(class_map):\n",
        "    class_map = {value.lower():key for key, value in class_map.items()}\n",
        "\n",
        "    class_map[\"street sign\"] = class_map.pop(\"traffic sign\")\n",
        "    class_map[\"cow\"] = class_map.pop(\"bull\")\n",
        "    class_map[\"eye glasses\"] = class_map.pop(\"glasses\")\n",
        "    class_map[\"shoe\"] = class_map.pop(\"boot\")\n",
        "    class_map[\"hair drier\"] = class_map.pop(\"hair dryer\")\n",
        "    class_map[\"donut\"] = class_map.pop(\"doughnut\")\n",
        "    class_map[\"microwave\"] = class_map.pop(\"microwave oven\")\n",
        "    class_map[\"cell phone\"] = class_map.pop(\"telephone\")\n",
        "    class_map[\"keyboard\"] = class_map.pop(\"computer keyboard\")\n",
        "    class_map[\"remote\"] = class_map.pop(\"remote control\")\n",
        "    class_map[\"mouse\"] = class_map.pop(\"computer mouse\")\n",
        "    class_map[\"tv\"] = class_map.pop(\"television\")\n",
        "    class_map[\"dining table\"] = class_map.pop(\"kitchen & dining room table\")\n",
        "    class_map[\"potted plant\"] = class_map.pop(\"plant\")\n",
        "    class_map[\"skis\"] = class_map.pop(\"ski\")\n",
        "    class_map[\"sports ball\"] = class_map.pop(\"volleyball\")\n",
        "    class_map[\"cup\"] = class_map.pop(\"coffee cup\")\n",
        "    class_map[\"frisbee\"] = class_map.pop(\"flying disc\")\n",
        "\n",
        "    return {value:key for key, value in class_map.items()}\n",
        "\n",
        "def remove_non_coco_labels(class_id_to_coco_label_map):\n",
        "    coco_list  = list(coco.values())\n",
        "    class_id_to_only_coco_map = {}\n",
        "    for key,val in class_id_to_coco_label_map.items():\n",
        "        if val in coco_list:\n",
        "            class_id_to_only_coco_map[key] = val\n",
        "    return class_id_to_only_coco_map\n",
        "\n",
        "def get_image_labels_with_bbox(metadata):\n",
        "    labes_bboxes = []\n",
        "    for entry in metadata:\n",
        "        bbox = [float(i) for i in entry[3:7]]\n",
        "        labes_bboxes.append([class_id_to_coco_label_map[entry[1]],bbox])\n",
        "    return labes_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRo4LWEXahhF"
      },
      "outputs": [],
      "source": [
        "coco = get_coco_labels()\n",
        "coco_readable_to_index = {value:key for key, value in coco.items()}\n",
        "get_downloadable_labels_str(coco)\n",
        "# clone repository in the terminal, run it locally using commands with returned string from method \"get_downloadable_labels_str(coco)\" and upload to appropriate path in Google Drive(\"ml_project/OIDv4_ToolKit/OID/Dataset\")\n",
        "# git clone https://github.com/EscVM/OIDv4_ToolKit.git\n",
        "# cd OIDv4_ToolKit/\n",
        "# !pip3 install -r requirements.txt\n",
        "# python main.py downloader --classes <paste_here_your_string> --type_csv <validation/test/train> --limit XX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiUanoJbahhH"
      },
      "outputs": [],
      "source": [
        "# obtain all needed dicts\n",
        "class_id_to_open_image_label_map = get_class_id_to_open_image_label_map()\n",
        "class_id_to_coco_label_map =  convert_open_image_label_to_coco(class_id_to_open_image_label_map)\n",
        "class_id_to_coco_label_map = remove_non_coco_labels(class_id_to_coco_label_map)\n",
        "all_images_metadata_dict = get_all_images_metadata_dict()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNLeyEmGPaxo"
      },
      "source": [
        "# Przetwarzanie odpowiednich danych i parametrów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbPMPRrfND1_"
      },
      "outputs": [],
      "source": [
        "def predict(my_image, width=None, height=None):\n",
        "    x = image.img_to_array(my_image)\n",
        "    if width is not None and height is not None:\n",
        "        x = tf.image.resize(x, [width, height], preserve_aspect_ratio=True)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    start_time = time.time()\n",
        "    preds = detector(x)\n",
        "    end_time = time.time()\n",
        "    inference_time = end_time-start_time\n",
        "    # print(\"Inference time: \", inference_time)\n",
        "    return preds, inference_time\n",
        "\n",
        "def predict_single_image(path, width=None, height=None):\n",
        "    image_name = os.path.basename(path).split(\".\")[0]\n",
        "    image_ = Image.open(path)\n",
        "    result, inference_time = predict(image_,width,height)\n",
        "    results = {key:value.numpy() for key,value in result.items()}\n",
        "    return results, image_name, inference_time\n",
        "\n",
        "def compute_iou(groundtruth_box, detection_box):\n",
        "    g_xmin, g_xmax, g_ymin, g_ymax = groundtruth_box\n",
        "    d_ymin, d_xmin, d_ymax, d_xmax = detection_box\n",
        "\n",
        "    xa = max(g_xmin, d_xmin)\n",
        "    ya = max(g_ymin, d_ymin)\n",
        "    xb = min(g_xmax, d_xmax)\n",
        "    yb = min(g_ymax, d_ymax)\n",
        "\n",
        "    intersection = max(0, xb - xa + 1) * max(0, yb - ya + 1)\n",
        "\n",
        "    boxAArea = (g_xmax - g_xmin + 1) * (g_ymax - g_ymin + 1)\n",
        "    boxBArea = (d_xmax - d_xmin + 1) * (d_ymax - d_ymin + 1)\n",
        "\n",
        "    return intersection / float(boxAArea + boxBArea - intersection)\n",
        "\n",
        "def update_confusion_matrix(oryginal_label_bbox, detected_label_bbox):\n",
        "    if detected_label_bbox == None:\n",
        "        confusion_matrix[coco_readable_to_index[oryginal_label_bbox[0]]-1][-1] += 1\n",
        "    else:\n",
        "        confusion_matrix[coco_readable_to_index[oryginal_label_bbox[0]]-1][coco_readable_to_index[detected_label_bbox[0]]-1] += 1\n",
        "\n",
        "def perform_analysis(model_result, image_name):\n",
        "    image_metadata_list = all_images_metadata_dict[image_name]\n",
        "    labels_bboxes_original = get_image_labels_with_bbox(image_metadata_list)\n",
        "\n",
        "    detected_classes = model_result['detection_classes'][0]\n",
        "    detected_classes_accuracy = model_result['detection_scores'][0]\n",
        "    detected_classes_bboxes = model_result['detection_boxes'][0]\n",
        "\n",
        "    labels_bboxes_detected = []\n",
        "    for d_class, score, bbox in zip(detected_classes,detected_classes_accuracy,detected_classes_bboxes):\n",
        "        if score >= 0.5:\n",
        "            labels_bboxes_detected.append([coco[d_class], list(bbox)])\n",
        "    for bbox_oryginal in labels_bboxes_original:\n",
        "        tmp = []\n",
        "        best_detected_bbox = None\n",
        "        for bbox_detected in labels_bboxes_detected:\n",
        "            iou = compute_iou(bbox_oryginal[1], bbox_detected[1])\n",
        "            if iou >= 0.5:\n",
        "                tmp.append([iou,bbox_detected])\n",
        "        if len(tmp) > 0:\n",
        "            tmp.sort(key = lambda x: x[0])\n",
        "            best_detected_bbox = tmp[-1][1]\n",
        "        update_confusion_matrix(bbox_oryginal, best_detected_bbox)\n",
        "\n",
        "def run_for_given_directory(dir_name):\n",
        "    global confusion_matrix;\n",
        "    confusion_matrix = [[0]*91 for i in range(90)]\n",
        "    dataset_path = \"OID/Dataset/train\"\n",
        "    subdirectory = dir_name\n",
        "    images = os.listdir(dataset_path + \"/\" + subdirectory)\n",
        "    val_err = 0\n",
        "    print(\"subdirectory: \" + subdirectory)\n",
        "    for image_ in images:\n",
        "        if image_.endswith(\".jpg\"):\n",
        "            print(\"processing image: \" + str(image_))\n",
        "            full_image_path = dataset_path + \"/\" + subdirectory + \"/\" + image_\n",
        "            try:\n",
        "                results, image_name = predict_single_image(full_image_path)\n",
        "            except ValueError:\n",
        "                print(\"Val error for picture: \", image_)\n",
        "                val_err += 1\n",
        "                continue\n",
        "            try:\n",
        "                perform_analysis(results, image_name)\n",
        "            except KeyError:\n",
        "                print(\"Key error for picture: \", image_)\n",
        "                continue\n",
        "\n",
        "def get_all_detections(class_name):\n",
        "    return confusion_matrix[coco_readable_to_index[class_name]-1][:-1]\n",
        "\n",
        "def get_TP(class_name):\n",
        "    return confusion_matrix[coco_readable_to_index[class_name]-1][coco_readable_to_index[class_name]-1]\n",
        "\n",
        "def get_FN(class_name):\n",
        "    return confusion_matrix[coco_readable_to_index[class_name]-1][-1]\n",
        "\n",
        "def get_FP(class_name):\n",
        "    return sum(get_all_detections(class_name)) - get_TP(class_name)\n",
        "\n",
        "def get_precision(class_name):\n",
        "    try:\n",
        "        return get_TP(class_name) / get_all_detections(class_name)\n",
        "    except ZeroDivisionError:\n",
        "        return 0    \n",
        "\n",
        "def get_recall(class_name):\n",
        "    try:\n",
        "        return get_TP(class_name) / ((get_TP(class_name))+get_FN(class_name))\n",
        "    except ZeroDivisionError:\n",
        "        return 0     \n",
        "\n",
        "def get_F1_score(class_name):\n",
        "    numerator = 2 * get_TP(class_name)\n",
        "    denominator = numerator + get_FP(class_name) + get_FN(class_name)\n",
        "    try:\n",
        "        return numerator/denominator\n",
        "    except ZeroDivisionError:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ0b29AOPweI"
      },
      "source": [
        "# Skuteczność poszczególnej klasy i modelu dla konkretnej rozdzielczości"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIktFSJZahhI"
      },
      "outputs": [],
      "source": [
        "def draw_bar_chart(values, labels, title, filename):\n",
        "    _values, _labels = zip(*sorted(zip(values, labels)))\n",
        "    positions = np.arange(len(_values)) + 0.5\n",
        "    plt.figure(num=None, figsize=(27, 10))\n",
        "    plt.barh(positions, _values, align='center')\n",
        "    plt.yticks(positions, _labels)\n",
        "    plt.tick_params(axis='y', labelsize=30)\n",
        "    for index, v in enumerate(_values):\n",
        "        plt.text(v, index, \"{:.2f}\".format(v), fontsize=30)\n",
        "    plt.xlabel('')\n",
        "    plt.title(title, fontsize=30)\n",
        "    ax = plt.axes()\n",
        "    ax.xaxis.set_tick_params(labelsize=30)\n",
        "    ax.xaxis.grid(True)\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    plt.savefig(filename, papertype='a2')\n",
        "\n",
        "def get_time_for_resolutions(times_with_res , class_name):\n",
        "    time_with_res = []\n",
        "    for resolution in times_with_res:\n",
        "        print(resolution)\n",
        "        time_with_res.append((resolution[0], resolution[1], resolution[2][class_name]))\n",
        "    return time_with_res\n",
        "\n",
        "def read_time(model_name):\n",
        "    matrices = []\n",
        "    files = os.listdir(model_name)\n",
        "    for file in files:\n",
        "        if 'inference_time' in file:\n",
        "            resolution = file.split(\"_\")[0]\n",
        "            if resolution.split(\"x\")[0] == \"640\":\n",
        "                resolution_int = 0\n",
        "                resolution = \"Original\"\n",
        "            else:\n",
        "                resolution_int = int(resolution.split(\"x\")[0]) * int(resolution.split(\"x\")[1])\n",
        "            matrices.append((resolution_int, resolution, open_time(model_name + \"/\" + file)))\n",
        "    matrices.sort(key = lambda x: x[0])\n",
        "    return matrices\n",
        "\n",
        "def open_time(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        l = eval(f.read())\n",
        "    return l\n",
        "\n",
        "import itertools\n",
        "\n",
        "def draw_time(times_with_resolutions, name, model_names):\n",
        "    fig = plt.figure()\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,7)\n",
        "    model_names_cycle = itertools.cycle(model_names)\n",
        "    for time_with_resolution in times_with_resolutions:\n",
        "        time_with_resolution.pop(0)\n",
        "        x_positions = np.arange(len(time_with_resolution))\n",
        "        values = [i[2] for i in time_with_resolution]\n",
        "        labels = [i[1] for i in time_with_resolution]\n",
        "        plt.plot(x_positions, values, linestyle='dashed', linewidth = 3,\n",
        "        marker='o', markersize=12, label = next(model_names_cycle))\n",
        "    plt.xticks(x_positions, labels)\n",
        "    plt.legend(loc='best', prop={'size': 20})\n",
        "    plt.tick_params(axis=\"both\", labelsize=18)\n",
        "    plt.title(name, fontsize=20)\n",
        "    plt.xlabel(\"resolution\", fontsize=20)\n",
        "    plt.ylabel(\"time\", fontsize=20)\n",
        "    return fig\n",
        "\n",
        "def print_pdf_for_model_time(model_names):\n",
        "    times_with_res = []\n",
        "    for model_name in model_names:\n",
        "        times_with_res.append(read_time(model_name))\n",
        "    if len(model_names) > 1:\n",
        "        time_pp = PdfPages(\"inference_time_by_resolution_comparison.pdf\")\n",
        "    else:\n",
        "        time_pp = PdfPages(model_names[0] + \"_inference_time_by_resolution.pdf\")\n",
        "    time = []\n",
        "    for class_name in coco.values():\n",
        "        for time_with_res in times_with_res:\n",
        "            time.append(get_time_for_resolutions(time_with_res, class_name))\n",
        "        time_pp.savefig(draw_time(time, class_name, model_names))\n",
        "        time.clear()\n",
        "    time_pp.close()\n",
        "\n",
        "def draw_normalized_TP_graph(model_name, width, height):\n",
        "    tmp = []\n",
        "    for row in confusion_matrix:\n",
        "        normalized_row = []\n",
        "        for value in row:\n",
        "            normalized_row.append(value/(sum(row)))\n",
        "        tmp.append(normalized_row)\n",
        "    diag = [ tmp[i][i] for i in range(len(tmp)) ]\n",
        "    diag = diag[:-1]\n",
        "    coco_labels = list(get_coco_labels().values())\n",
        "    print()\n",
        "    title = \"Normalized TP\"\n",
        "    folder = str(model_name) + '/'\n",
        "    filename = folder + str(model_name) + '_' + str(width) + 'x' + str(height) + \"_Normalized_TP.pdf\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    draw_bar_chart(diag,coco_labels,title,filename)\n",
        "\n",
        "def draw_f1_score_graph(model_name, width, height):\n",
        "    coco_labels = list(coco.values())\n",
        "    f1_scores = []\n",
        "    for val in coco_labels:\n",
        "        f1_scores.append(get_F1_score(val))\n",
        "    title = \"F1 Scores\"\n",
        "    folder = str(model_name) + '/'\n",
        "    filename = folder + str(model_name) + '_' + str(width) + 'x' + str(height) + \"_F1_scores.pdf\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    draw_bar_chart(f1_scores, coco_labels, title, filename)\n",
        "\n",
        "def draw_recall_graph(model_name, width, height):\n",
        "    coco_labels = list(coco.values())\n",
        "    recalls = []\n",
        "    for val in coco_labels:\n",
        "        recalls.append(get_recall(val))\n",
        "    title = \"Recalls\"\n",
        "    folder = str(model_name) + '/'\n",
        "    filename = folder + str(model_name) + '_' + str(width) + 'x' + str(height) + \"_recalls.pdf\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    draw_bar_chart(recalls, coco_labels, title, filename)\n",
        "\n",
        "def draw_precision_graph(model_name, width, height):\n",
        "    coco_labels = list(coco.values())\n",
        "    precisions = []\n",
        "    for val in coco_labels:\n",
        "        precisions.append(get_F1_score(val))\n",
        "    title = \"Precisions\"\n",
        "    folder = str(model_name) + '/'\n",
        "    filename = folder + str(model_name) + '_' + str(width) + 'x' + str(height) + \"_precisions.pdf\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    draw_bar_chart(precisions, coco_labels, title, filename)\n",
        "\n",
        "# rows equal to coco label id -1\n",
        "# same with columns\n",
        "# rows -> original classes\n",
        "# columns -> detected classes\n",
        "# last column indicates not found\n",
        "\n",
        "def draw_graphs(model_name, width, height):\n",
        "    draw_normalized_TP_graph(model_name, width, height)\n",
        "    draw_f1_score_graph(model_name, width, height)\n",
        "    draw_recall_graph(model_name, width, height)\n",
        "    draw_precision_graph(model_name, width, height)\n",
        "\n",
        "def test_all_dataset(model_name, width=None, height=None):\n",
        "    val_err = 0\n",
        "    dataset_path = \"OID/Dataset/train\"\n",
        "    directory_contents = os.listdir(dataset_path)\n",
        "    global time_dict\n",
        "    time_dict = {}\n",
        "    directory_contents_ = [directory_contents[36],directory_contents[21],directory_contents[17]]\n",
        "    for subdirectory in directory_contents_:\n",
        "        images = os.listdir(dataset_path + \"/\" + subdirectory)\n",
        "        print(\"subdirectory: \" + subdirectory)\n",
        "        inference_time_per_class = 0\n",
        "        for image_ in images[:2]:\n",
        "            if image_.endswith(\".jpg\"):\n",
        "                print(\"processing image: \" + str(image_))\n",
        "                full_image_path = dataset_path + \"/\" + subdirectory + \"/\" + image_\n",
        "                try:\n",
        "                    results, image_name, inference_time = predict_single_image(full_image_path, width, height)\n",
        "                    inference_time_per_class += inference_time\n",
        "                except ValueError:\n",
        "                    val_err += 1\n",
        "                    continue\n",
        "                perform_analysis(results, image_name)\n",
        "        # inference_time_mean = inference_time_per_class/len(images)        \n",
        "        inference_time_mean = inference_time_per_class/2\n",
        "        time_dict[subdirectory.lower()] = inference_time_mean\n",
        "    draw_graphs(model_name, width, height)\n",
        "    return time_dict\n",
        "\n",
        "def save_confusion_matrix(model_name, width=None, height=None):\n",
        "    mat = np.matrix(confusion_matrix)\n",
        "    folder = str(model_name)+ \"/\"\n",
        "    name = folder + str(width) +'x' + str(height) + \"_confusion_matrix_\" + str(model_name) + '.txt'\n",
        "    os.makedirs(os.path.dirname(name), exist_ok=True)\n",
        "    with open(name,'wb') as f:\n",
        "        for line in mat:\n",
        "            np.savetxt(f, line, fmt='%.2f')\n",
        "    return name\n",
        "\n",
        "def save_inference_time(model_name, width=None, height=None):\n",
        "    folder = str(model_name)+ \"/\"\n",
        "    name = folder + str(width) +'x' + str(height) + \"_inference_time_\" + str(model_name) + '.txt'\n",
        "    os.makedirs(os.path.dirname(name), exist_ok=True)\n",
        "    with open(name,'w') as f:\n",
        "        f.write(str(time_dict))\n",
        "    return name\n",
        "\n",
        "def test_resolution(model_name, width=None, height=None):\n",
        "    resolution = str(width) +'x' + str(height)\n",
        "    test_all_dataset(model_name, width, height)\n",
        "    name = save_confusion_matrix(model_name, width, height)\n",
        "    confusion_matrix_names.append(name)\n",
        "    inference_time_name = save_inference_time(model_name, width, height)\n",
        "    inference_time_names.append(inference_time_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaDBmTHIP0UU"
      },
      "source": [
        "# Trenowanie modelu dla różnych rozdzielczości"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpfaDN9AahhL"
      },
      "outputs": [],
      "source": [
        "resolutions = [(3840,2160),(2560,1440),(1920,1200),(1920,1080),(1680,1050),(1600,900),(1360,768),(1024,768),(800,600)]\n",
        "confusion_matrix_names = []\n",
        "inference_time_names = []\n",
        "time_dict = {}\n",
        "\n",
        "# # ssd+mobilenet\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1\")\n",
        "# confusion_matrix = [[0]*4 for i in range(3)]\n",
        "confusion_matrix = [[0]*91 for i in range(90)]\n",
        "test_resolution('ssd+mobilenet_v2', 640, 640)\n",
        "\n",
        "for resolution in resolutions:\n",
        "    confusion_matrix = [[0]*91 for i in range(90)]\n",
        "    test_resolution('ssd+mobilenet_v2',resolution[0],resolution[1])\n",
        "\n",
        "# faster_rcnn+resnet\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\")\n",
        "# confusion_matrix = [[0]*4 for i in range(3)]\n",
        "confusion_matrix = [[0]*91 for i in range(90)]\n",
        "test_resolution('faster_rcnn+resnet', 640, 640)\n",
        "\n",
        "for resolution in resolutions:\n",
        "    confusion_matrix = [[0]*91 for i in range(90)]\n",
        "    test_resolution('faster_rcnn+resnet',resolution[0],resolution[1])\n",
        "\n",
        "# retinanet+resnet\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1\")\n",
        "# confusion_matrix = [[0]*4 for i in range(3)]\n",
        "confusion_matrix = [[0]*91 for i in range(90)]\n",
        "test_resolution('retinanet+resnet', 640, 640)\n",
        "\n",
        "for resolution in resolutions:\n",
        "    confusion_matrix = [[0]*91 for i in range(90)]\n",
        "    test_resolution('retinanet+resnet',resolution[0],resolution[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCVsmFoGUVee"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Porównanie efektywności w funkcji rozdzielczości dla konkretnej klasy i modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxBpo9ciY4go"
      },
      "outputs": [],
      "source": [
        "def open_matrix(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        l = [[int(float(num)) for num in line.split(' ')] for line in f]\n",
        "    return l\n",
        "\n",
        "coco_readable_to_index = {value:key for key, value in coco.items()}\n",
        "\n",
        "def get_all_detections(confusion_matrix, class_name):\n",
        "    return confusion_matrix[coco_readable_to_index[class_name]-1][:-1]\n",
        "\n",
        "def get_TP(confusion_matrix, class_name):\n",
        "    return confusion_matrix[coco_readable_to_index[class_name]-1][coco_readable_to_index[class_name]-1]\n",
        "\n",
        "def get_FN(confusion_matrix, class_name):\n",
        "    return confusion_matrix[coco_readable_to_index[class_name]-1][-1]\n",
        "\n",
        "def get_FP(confusion_matrix, class_name):\n",
        "    return sum(get_all_detections(confusion_matrix, class_name)) - get_TP(confusion_matrix, class_name)\n",
        "\n",
        "def get_precision(confusion_matrix, class_name):\n",
        "    try:\n",
        "        return get_TP(confusion_matrix, class_name) / sum(get_all_detections(confusion_matrix, class_name))\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "        \n",
        "def get_recall(confusion_matrix, class_name):\n",
        "    try:\n",
        "        return get_TP(confusion_matrix, class_name) / ((get_TP(confusion_matrix, class_name))+get_FN(confusion_matrix, class_name))\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "\n",
        "def get_F1_score(confusion_matrix, class_name):\n",
        "    numerator = 2 * get_TP(confusion_matrix, class_name)\n",
        "    denominator = numerator + get_FP(confusion_matrix, class_name) + get_FN(confusion_matrix, class_name)\n",
        "    try:\n",
        "        return numerator/denominator\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "\n",
        "def get_normalized(confusion_matrix, class_name):\n",
        "    tmp = []\n",
        "    for row in confusion_matrix:\n",
        "        normalized_row = []\n",
        "        for value in row:\n",
        "            normalized_row.append(value/(sum(row)))\n",
        "        tmp.append(normalized_row)\n",
        "    return tmp[coco_readable_to_index[class_name]-1][coco_readable_to_index[class_name]-1]\n",
        "\n",
        "def read_matrices(model_name):\n",
        "    matrices = []\n",
        "    files = os.listdir(model_name)\n",
        "    for file in files:\n",
        "        if 'confusion_matrix' in file:\n",
        "            resolution = file.split(\"_\")[0]\n",
        "            if resolution.split(\"x\")[0] == \"640\":\n",
        "                resolution_int = 0\n",
        "                resolution = \"Original\"\n",
        "            else:\n",
        "                resolution_int = int(resolution.split(\"x\")[0]) * int(resolution.split(\"x\")[1])\n",
        "            matrices.append((resolution_int, resolution, open_matrix(model_name + \"/\" + file)))\n",
        "    matrices.sort(key = lambda x: x[0])\n",
        "    return matrices\n",
        "\n",
        "def get_normalized_for_resolutions(matrices_with_res , class_name):\n",
        "    normalized_with_res = []\n",
        "    for resolution in matrices_with_res:\n",
        "        normalized_with_res.append((resolution[0], resolution[1], get_normalized(resolution[2],class_name)))\n",
        "    return normalized_with_res\n",
        "\n",
        "def get_f1_for_resolutions(matrices_with_res , class_name):\n",
        "    f1_with_res = []\n",
        "    for resolution in matrices_with_res:\n",
        "        f1_with_res.append((resolution[0], resolution[1], get_F1_score(resolution[2],class_name)))\n",
        "    return f1_with_res\n",
        "\n",
        "def get_precision_for_resolutions(matrices_with_res , class_name):\n",
        "    precision_with_res = []\n",
        "    for resolution in matrices_with_res:\n",
        "        precision_with_res.append((resolution[0], resolution[1], get_precision(resolution[2],class_name)))\n",
        "    return precision_with_res\n",
        "\n",
        "def get_recall_for_resolutions(matrices_with_res , class_name):\n",
        "    recall_with_res = []\n",
        "    for resolution in matrices_with_res:\n",
        "        recall_with_res.append((resolution[0], resolution[1], get_recall(resolution[2],class_name)))\n",
        "    return recall_with_res\n",
        "\n",
        "    \n",
        "def draw(resolutions_with_values, name, model_names):\n",
        "    print(resolutions_with_values)\n",
        "    fig = plt.figure()\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,7)\n",
        "    model_names_cycle = itertools.cycle(model_names)\n",
        "    for resolution_with_value in resolutions_with_values:\n",
        "        resolution_with_value.pop(0)\n",
        "        x_positions = np.arange(len(resolution_with_value))\n",
        "        values = [i[2] for i in resolution_with_value]\n",
        "        labels = [i[1] for i in resolution_with_value]\n",
        "        plt.plot(x_positions, values, linestyle='dashed', linewidth = 3,\n",
        "        marker='o', markersize=12, label = next(model_names_cycle))\n",
        "    plt.xticks(x_positions, labels)\n",
        "    plt.legend(loc='best', prop={'size': 20})\n",
        "    plt.tick_params(axis=\"both\", labelsize=18)\n",
        "    plt.title(name, fontsize=20)\n",
        "    plt.xlabel(\"resolution\", fontsize=20)\n",
        "    plt.ylabel(\"value\", fontsize=20)\n",
        "    return fig\n",
        "\n",
        "def print_pdf_for_model(model_names):\n",
        "    matrices_with_res = []\n",
        "    for model_name in model_names:\n",
        "        matrices_with_res.append(read_matrices(model_name))\n",
        "    if len(model_names) > 1:\n",
        "        f1_pp = PdfPages(\"f1_score_by_resolution_comparison.pdf\")\n",
        "        precision_pp = PdfPages(\"precision_by_resolution_comparison.pdf\")\n",
        "        recall_pp = PdfPages(\"recall_by_resolution_comparison.pdf\")\n",
        "        normalized_pp = PdfPages(\"normalized_score_by_resolution_comparison.pdf\")\n",
        "    else:\n",
        "        f1_pp = PdfPages(model_names[0] + \"_f1_score_by_resolution.pdf\")\n",
        "        precision_pp = PdfPages(model_names[0] + \"_precision_by_resolution.pdf\")\n",
        "        recall_pp = PdfPages(model_names[0] + \"_recall_by_resolution.pdf\")\n",
        "        normalized_pp = PdfPages(model_names[0] + \"_normalized_score_by_resolution.pdf\")\n",
        "    f1, normalized, precision, recall = ([] for i in range(4))\n",
        "    for class_name in coco.values():\n",
        "        for matrix_with_res in matrices_with_res:\n",
        "            f1.append(get_f1_for_resolutions(matrix_with_res, class_name))\n",
        "            normalized.append(get_normalized_for_resolutions(matrix_with_res, class_name))\n",
        "            precision.append(get_precision_for_resolutions(matrix_with_res, class_name))\n",
        "            recall.append(get_recall_for_resolutions(matrix_with_res, class_name))\n",
        "        print(f1)        \n",
        "        f1_pp.savefig(draw(f1, class_name, model_names))\n",
        "        normalized_pp.savefig(draw(normalized, class_name, model_names))\n",
        "        precision_pp.savefig(draw(precision, class_name, model_names))\n",
        "        recall_pp.savefig(draw(recall, class_name, model_names))\n",
        "        f1.clear()\n",
        "        normalized.clear()\n",
        "        precision.clear()\n",
        "        recall.clear()\n",
        "    f1_pp.close()\n",
        "    precision_pp.close()\n",
        "    recall_pp.close()\n",
        "    normalized_pp.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DT71gr_mbuS"
      },
      "outputs": [],
      "source": [
        "print_pdf_for_model([\"ssd+mobilenet_v2\", \"faster_rcnn+resnet\", \"retinanet+resnet\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjyKuEY1Vw3o"
      },
      "source": [
        "# Wizualizacja macierzy pomyłek dla konkretnej klasy, modelu i rozdzielczości"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KsM55G5m-O4"
      },
      "outputs": [],
      "source": [
        "def draw_confusion_matrix(filename):\n",
        "    coco = get_coco_labels()\n",
        "    names =[]\n",
        "    for key, val in coco.items():\n",
        "        names.append(val)\n",
        "\n",
        "    array = open_matrix(filename)\n",
        "\n",
        "    new_arr = [row[:-1] for row in array]\n",
        "    new_arr = np.array(new_arr)\n",
        "    idx =[0,12,76]\n",
        "    print(new_arr[np.ix_(idx, idx)])\n",
        "    new_arr = new_arr[np.ix_(idx, idx)]\n",
        "\n",
        "    df_cm = pd.DataFrame(new_arr, names, names)\n",
        "    fig = plt.figure(figsize=(9,9))\n",
        "    sn.set(font_scale=2.4) # for label size\n",
        "    sn.heatmap(df_cm, annot=True, fmt='g', annot_kws={\"size\": 30}) # font size\n",
        "\n",
        "    pdf = PdfPages(\"retinanet+resnet_conf_matrix.pdf\")\n",
        "    pdf.savefig(fig)\n",
        "    pdf.close()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wjtl4S83638"
      },
      "outputs": [],
      "source": [
        "# draw_confusion_matrix(\"ssd+mobilenet_v2/640x640_confusion_matrix_ssd+mobilenet_v2.txt\")\n",
        "# draw_confusion_matrix(\"faster_rcnn+resnet/640x640_confusion_matrix_faster_rcnn+resnet.txt\")\n",
        "draw_confusion_matrix(\"retinanet+resnet/640x640_confusion_matrix_retinanet+resnet.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Porównanie czasu uczenia w funkcji rozdzielczości dla konkretnej klasy i modelu"
      ],
      "metadata": {
        "id": "pVyuhvldiU1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_for_resolutions(times_with_res , class_name):\n",
        "    time_with_res = []\n",
        "    for resolution in times_with_res:\n",
        "        print(resolution)\n",
        "        time_with_res.append((resolution[0], resolution[1], resolution[2][class_name]))\n",
        "    return time_with_res\n",
        "\n",
        "def read_time(model_name):\n",
        "    matrices = []\n",
        "    files = os.listdir(model_name)\n",
        "    for file in files:\n",
        "        if 'inference_time' in file:\n",
        "            resolution = file.split(\"_\")[0]\n",
        "            if resolution.split(\"x\")[0] == \"640\":\n",
        "                resolution_int = 0\n",
        "                resolution = \"Original\"\n",
        "            else:\n",
        "                resolution_int = int(resolution.split(\"x\")[0]) * int(resolution.split(\"x\")[1])\n",
        "            matrices.append((resolution_int, resolution, open_time(model_name + \"/\" + file)))\n",
        "    matrices.sort(key = lambda x: x[0])\n",
        "    return matrices\n",
        "\n",
        "def open_time(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        l = eval(f.read())\n",
        "    return l\n",
        "\n",
        "def draw_time(times_with_resolutions, name, model_names):\n",
        "    fig = plt.figure()\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,7)\n",
        "    model_names_cycle = itertools.cycle(model_names)\n",
        "    for time_with_resolution in times_with_resolutions:\n",
        "        time_with_resolution.pop(0)\n",
        "        x_positions = np.arange(len(time_with_resolution))\n",
        "        values = [i[2] for i in time_with_resolution]\n",
        "        labels = [i[1] for i in time_with_resolution]\n",
        "        plt.plot(x_positions, values, linestyle='dashed', linewidth = 3,\n",
        "        marker='o', markersize=12, label = next(model_names_cycle))\n",
        "    plt.xticks(x_positions, labels)\n",
        "    plt.legend(loc='best', prop={'size': 20})\n",
        "    plt.tick_params(axis=\"both\", labelsize=18)\n",
        "    plt.title(name, fontsize=20)\n",
        "    plt.xlabel(\"resolution\", fontsize=20)\n",
        "    plt.ylabel(\"time\", fontsize=20)\n",
        "    return fig\n",
        "\n",
        "def print_pdf_for_model_time(model_names):\n",
        "    times_with_res = []\n",
        "    for model_name in model_names:\n",
        "        times_with_res.append(read_time(model_name))\n",
        "    if len(model_names) > 1:\n",
        "        time_pp = PdfPages(\"inference_time_by_resolution_comparison.pdf\")\n",
        "    else:\n",
        "        time_pp = PdfPages(model_names[0] + \"_inference_time_by_resolution.pdf\")\n",
        "    time = []\n",
        "    for class_name in coco.values():\n",
        "        for time_with_res in times_with_res:\n",
        "            time.append(get_time_for_resolutions(time_with_res, class_name))\n",
        "        time_pp.savefig(draw_time(time, class_name, model_names))\n",
        "        time.clear()\n",
        "    time_pp.close()"
      ],
      "metadata": {
        "id": "I6n2npCUid-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_pdf_for_model_time([\"ssd+mobilenet_v2\", \"faster_rcnn+resnet\", \"retinanet+resnet\"])"
      ],
      "metadata": {
        "id": "Ogc4aYtMiqUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}